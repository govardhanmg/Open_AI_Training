{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govardhanmg/Open_AI_Training/blob/main/Chatcompletions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgXtw_8WgrXp",
        "outputId": "b79c85b8-0935-4229-ae7d-c0a5e56c49da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.13.3\n",
            "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.13.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.13.3)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (2.20.1)\n",
            "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.13.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1712333180112
        },
        "id": "Uoi6LNgZgrXr"
      },
      "outputs": [],
      "source": [
        "# Add Azure OpenAI package\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1712333182445
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "wym1E9bmgrXr"
      },
      "outputs": [],
      "source": [
        "azure_oai_endpoint =\"https://eyuser11.openai.azure.com/\"\n",
        "azure_oai_key =\"31184323c72140578cb882d3f103a7a7\"\n",
        "azure_oai_deployment =\"gpt-35-turbo-16k\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1712333183879
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "-kGr89tIgrXs"
      },
      "outputs": [],
      "source": [
        "# Initialize the Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "        azure_endpoint = azure_oai_endpoint,\n",
        "        api_key=azure_oai_key,\n",
        "        api_version=\"2024-02-15-preview\"\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1712333189626
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQoe85t1grXs",
        "outputId": "db1bc828-732d-4e1e-c5c5-f7af4699019a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-A436VuekdhlKLTyGxIVNh1wS8wnSV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, absolutely! Polar bears are big fans of pizzas. In fact, they're known to have pizza parties on icebergs. Just make sure to bring extra toppings because they have quite the appetite!\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1725528607, model='gpt-35-turbo-16k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=41, prompt_tokens=60, total_tokens=101), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0.7,\n",
        "    max_tokens=400,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do polar bears support pizzas too?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1712333189871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnL-JmQtgrXt",
        "outputId": "c3d44941-c744-4a25-ef55-80275a806f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Oh, absolutely! Polar bears are big fans of pizzas. In fact, they're known to have pizza parties on icebergs. Just make sure to bring extra toppings because they have quite the appetite!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generated_text = response.choices[0].message.content\n",
        "\n",
        "# Print the response\n",
        "print(\"Response: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "iMnqb-jBgrXt"
      },
      "source": [
        "**Maintain Chat History**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1712333260307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "RPBlJZCBgrXv"
      },
      "outputs": [],
      "source": [
        "# To maintain chat hisotry, we initialize messages array and append all interactions to the messages array\n",
        "messages_array = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"}\n",
        "\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1712333261573
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "xQYRsOUngrXv"
      },
      "outputs": [],
      "source": [
        "input_text = \"Do polar bears support pizzas too?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1712333265598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-385kA3rgrXw",
        "outputId": "b503320c-bd27-4e5e-8bd0-2696f801d6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Oh, definitely! Polar bears are big fans of pizzas, especially those topped with fish and seal meat. They even have their own special recipe called the \"Arctic Delight\" that includes extra ice cubes as a topping.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "messages_array.append({\"role\": \"user\", \"content\": input_text})\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0.7,\n",
        "    max_tokens=1200,\n",
        "    messages=messages_array\n",
        ")\n",
        "generated_text = response.choices[0].message.content\n",
        "# Add generated text to messages array\n",
        "messages_array.append({\"role\": \"system\", \"content\": generated_text})\n",
        "\n",
        "# Print generated text\n",
        "print(\"Summary: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "7eaJw8PtgrXx"
      },
      "source": [
        "**Let's check out the messages array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1712333314293
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsyj8I7MgrXy",
        "outputId": "205cd49b-fc57-45db-ccfa-7975010b9d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a helpful assistant with a lot of humor.'}, {'role': 'user', 'content': 'Do penguins like pizzas?'}, {'role': 'assistant', 'content': 'Yes, penguins like pizza very much. They also like chips and hummus.'}, {'role': 'user', 'content': 'Do polar bears support pizzas too?'}, {'role': 'system', 'content': 'Oh, definitely! Polar bears are big fans of pizzas, especially those topped with fish and seal meat. They even have their own special recipe called the \"Arctic Delight\" that includes extra ice cubes as a topping.'}]\n"
          ]
        }
      ],
      "source": [
        "print(messages_array)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcS0dGIFhXmb"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}